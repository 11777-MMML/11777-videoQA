{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df1 = pd.read_csv(\"train_split_1.csv\")\n",
    "df2 = pd.read_csv(\"train_split_2.csv\")\n",
    "df3 = pd.read_csv(\"train_split_3.csv\")\n",
    "df4 = pd.read_csv(\"train_split_4.csv\")\n",
    "df = pd.concat([df1, df2, df3, df4], ignore_index=True)\n",
    "df[\"video_id\"] = df[\"video_id\"].astype(np.int64)\n",
    "train = pd.read_csv(\"train_with_captions.csv\")\n",
    "val = pd.read_csv(\"val_with_captions.csv\")\n",
    "test = pd.read_csv(\"test_with_captions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34132, 34132, 4996, 4996, 8564, 8564)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.merge(train, df, on='video_id')\n",
    "df_val = pd.merge(val, df, on='video_id')\n",
    "df_test = pd.merge(test, df, on='video_id')\n",
    "len(train), len(df_train), len(val), len(df_val), len(test), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"train_with_captions_actions.csv\", index=False)\n",
    "df_val.to_csv(\"val_with_captions_actions.csv\", index=False)\n",
    "df_test.to_csv(\"test_with_captions_actions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['video_id', 'frame_count', 'width', 'height', 'question', 'answer',\n",
       "       'qid', 'type', 'a0', 'a1', 'a2', 'a3', 'a4', 'a0_cand0', 'a0_cand1',\n",
       "       'a0_cand2', 'a0_cand3', 'a0_cand4', 'a1_cand0', 'a1_cand1', 'a1_cand2',\n",
       "       'a1_cand3', 'a1_cand4', 'a2_cand0', 'a2_cand1', 'a2_cand2', 'a2_cand3',\n",
       "       'a2_cand4', 'a3_cand0', 'a3_cand1', 'a3_cand2', 'a3_cand3', 'a3_cand4',\n",
       "       'a4_cand0', 'a4_cand1', 'a4_cand2', 'a4_cand3', 'a4_cand4', 'caption',\n",
       "       'caption_confidence', 'video_path', 'result0', 'conf0', 'result1',\n",
       "       'conf1', 'result2', 'conf2', 'result3', 'conf3', 'result4', 'conf4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sub_train = train[[\"video_id\", \"video_path\", \"caption\"]]\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sampa\\AppData\\Local\\Temp\\ipykernel_3396\\2187574375.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub_train[\"action_caption\"] = sub_train[\"result1\"]+\". \"+sub_train[\"caption\"]\n",
      "C:\\Users\\sampa\\AppData\\Local\\Temp\\ipykernel_3396\\2187574375.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub_val[\"action_caption\"] = sub_val[\"result1\"]+\". \"+sub_val[\"caption\"]\n",
      "C:\\Users\\sampa\\AppData\\Local\\Temp\\ipykernel_3396\\2187574375.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub_test[\"action_caption\"] = sub_test[\"result1\"]+\". \"+sub_test[\"caption\"]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"train_with_captions_actions.csv\")\n",
    "val = pd.read_csv(\"val_with_captions_actions.csv\")\n",
    "test = pd.read_csv(\"test_with_captions_actions.csv\")\n",
    "\n",
    "train = train.drop_duplicates(subset=['video_id'], keep='first')\n",
    "val = val.drop_duplicates(subset=['video_id'], keep='first')\n",
    "test = test.drop_duplicates(subset=['video_id'], keep='first')\n",
    "\n",
    "sub_train = train[[\"video_id\", 'video_path', \"caption\", \"result1\"]]\n",
    "sub_val = val[[\"video_id\", 'video_path', \"caption\", \"result1\"]]\n",
    "sub_test = test[[\"video_id\", 'video_path', \"caption\", \"result1\"]]\n",
    "\n",
    "sub_train[\"action_caption\"] = sub_train[\"result1\"]+\". \"+sub_train[\"caption\"]\n",
    "sub_val[\"action_caption\"] = sub_val[\"result1\"]+\". \"+sub_val[\"caption\"]\n",
    "sub_test[\"action_caption\"] = sub_test[\"result1\"]+\". \"+sub_test[\"caption\"]\n",
    "\n",
    "sub_train.to_csv(\"subtrain_with_captions_actions.csv\", index=False)\n",
    "sub_val.to_csv(\"subval_with_captions_actions.csv\", index=False)\n",
    "sub_test.to_csv(\"subtest_with_captions_actions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3870, 570, 1000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sub_train), len(sub_val), len(sub_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, BertModel, AutoTokenizer, AutoModel\n",
    "\n",
    "class TextLoader(data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        path: str\n",
    "    ):\n",
    "        self.path = path\n",
    "        self.csv = pd.read_csv(self.path)\n",
    "        self.num_answers = 5\n",
    "        self.action_key = 'result0'\n",
    "        self.description_key = 'caption'\n",
    "        self.target_length = 60\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        example = self.csv.iloc[index]\n",
    "\n",
    "        question = example[\"question\"]\n",
    "\n",
    "        answers = []\n",
    "\n",
    "        for i in range(self.num_answers):\n",
    "            answers.append(example[f'a{i}'])\n",
    "        \n",
    "        caption = example[self.description_key]\n",
    "        action = example[self.action_key]\n",
    "\n",
    "        text_reps = []\n",
    "        for answer in answers:\n",
    "            text_rep = [action, caption, question, answer]\n",
    "            text_rep_test = \" \".join(text_rep)\n",
    "            text_rep_test = text_rep_test.split(\" \")\n",
    "            text_rep = \" [SEP] \".join(text_rep)\n",
    "            text_rep = \"[CLS]\" + \" \" + text_rep\n",
    "\n",
    "            inputs = self.tokenizer(text_rep, return_tensors=\"pt\")\n",
    "\n",
    "            curr_tokens = inputs.input_ids.size()[-1]\n",
    "            \n",
    "            if  curr_tokens < self.target_length:\n",
    "                diff = self.target_length - curr_tokens\n",
    "\n",
    "                pad = [\"[PAD]\"]\n",
    "                padding = \" \".join(pad * diff)\n",
    "                text_rep = text_rep + \" \" + padding\n",
    "                text_reps.append(text_rep)\n",
    "        \n",
    "        return len(text_rep_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4996/4996 [00:13<00:00, 368.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = TextLoader('val_with_captions_actions.csv') \n",
    "loader = data.DataLoader(dataset, shuffle=False)\n",
    "\n",
    "_max = 0\n",
    "for i, batch in enumerate(tqdm(loader)):\n",
    "    _max = max(_max, batch.item())\n",
    "print(_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  2%|▏         | 731/34132 [00:37<28:40, 19.41it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_155249/1326597441.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mfeat2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mfeat2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "dataset = TextLoader('train_with_captions_actions.csv') \n",
    "loader = data.DataLoader(dataset, shuffle=False)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\") # device_map=\"auto\", max_memory=max_memory_mapping\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "feat1 = []\n",
    "feat2 = []\n",
    "\n",
    "for i, batch in enumerate(tqdm(loader)):\n",
    "    batch = map(lambda x: x[0], batch)\n",
    "    batch = list(batch)\n",
    "    inputs = tokenizer(batch, return_tensors=\"pt\")\n",
    "    inputs = inputs.to(model.device)\n",
    "    outputs = model(**inputs)\n",
    "    cls_token = outputs.pooler_output\n",
    "    cls_token = cls_token.unsqueeze(0).detach().cpu()\n",
    "    state = outputs.last_hidden_state\n",
    "    state = state.unsqueeze(0).detach().cpu()\n",
    "    if not len(feat1):\n",
    "        feat1 = cls_token\n",
    "    else:\n",
    "        feat1 = torch.cat([feat1, cls_token], dim=0)\n",
    "    if not len(feat2):\n",
    "        feat2 = state\n",
    "    else:\n",
    "        feat2 = torch.cat([feat2, state], dim=0)\n",
    "    del inputs, state, cls_token\n",
    "print(feat1.shape)\n",
    "print(feat2.shape)\n",
    "torch.save(feat1, \"bert_cls_feats.pt\")\n",
    "torch.save(feat2, \"bert_all_feats.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([34132]) torch.Size([4996]) torch.Size([8564])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "train, val, test = pd.read_csv(\"/mnt/adithya/moment_detr/csvs/train_with_captions_actions.csv\"), pd.read_csv(\"/mnt/adithya/moment_detr/csvs/val_with_captions_actions.csv\"), pd.read_csv(\"/mnt/adithya/moment_detr/csvs/test_with_captions_actions.csv\")\n",
    "train_ids = torch.from_numpy(train[\"video_id\"].to_numpy())\n",
    "val_ids = torch.from_numpy(val[\"video_id\"].to_numpy())\n",
    "test_ids = torch.from_numpy(test[\"video_id\"].to_numpy())\n",
    "torch.save(train_ids, \"/mnt/adithya/action_caption_dataset/bert_feats/train_video_ids.pt\")\n",
    "torch.save(val_ids, \"/mnt/adithya/action_caption_dataset/bert_feats/val_video_ids.pt\")\n",
    "torch.save(test_ids, \"/mnt/adithya/action_caption_dataset/bert_feats/test_video_ids.pt\")\n",
    "print(train_ids.shape, val_ids.shape, test_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('adi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1dfe2ea80f9dde804c12f385e3b7ddc064468faa70c678b79f7851865103f230"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
